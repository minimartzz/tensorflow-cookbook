{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Getting Started with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date | User | Change Type | Remarks |  \n",
    "| ---- | ---- | ----------- | ------- |\n",
    "| 03/09/2024   | Martin | Created   | Started chapter 1 | \n",
    "| 09/09/2024   | Martin | Update   | To page 55 - activation functions | \n",
    "| 08/10/2024   | Martin | Update   | Activation functions and sources for datasets | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Content\n",
    "\n",
    "* [Introduction](#introduction)\n",
    "* [Variables and Tensors](#variables-and-tensors)\n",
    "* [Activation Functions](#activation-functions)\n",
    "* [Working with Data Sources](#working-with-data-sources)\n",
    "* [Tensorflow Under the hood](#tensorflow-under-the-hood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"GRPC_VERBOSITY\"] = \"ERROR\"\n",
    "os.environ[\"GLOG_minloglevel\"] = \"2\"\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General workflow of Tensorflow:\n",
    "\n",
    "1. Import or generate datasets\n",
    "2. Transform and normalize data\n",
    "3. Partition datasets into training, test and validation sets\n",
    "4. Set algorithm parameters (hyperparameters)\n",
    "5. Initialize variables\n",
    "6. Define the model structure\n",
    "7. Declare loss function\n",
    "8. Initialise and train the model\n",
    "9. Evaluate the model\n",
    "10. Tune hyper parameters\n",
    "11. Deploy/ predict new outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss is: 0.313\n",
      "real label: 0 | fitted: 0\n",
      "real label: 1 | fitted: 1\n",
      "real label: 1 | fitted: 2\n",
      "real label: 2 | fitted: 1\n",
      "real label: 2 | fitted: 2\n",
      "real label: 2 | fitted: 2\n",
      "real label: 0 | fitted: 0\n",
      "real label: 2 | fitted: 2\n",
      "real label: 1 | fitted: 1\n",
      "real label: 2 | fitted: 2\n",
      "real label: 1 | fitted: 2\n",
      "real label: 0 | fitted: 0\n",
      "real label: 1 | fitted: 1\n",
      "real label: 0 | fitted: 0\n",
      "real label: 2 | fitted: 2\n",
      "real label: 2 | fitted: 2\n",
      "real label: 0 | fitted: 0\n",
      "real label: 2 | fitted: 2\n",
      "real label: 0 | fitted: 0\n",
      "real label: 1 | fitted: 1\n",
      "real label: 2 | fitted: 2\n",
      "real label: 0 | fitted: 0\n",
      "real label: 2 | fitted: 2\n",
      "real label: 1 | fitted: 1\n",
      "real label: 0 | fitted: 0\n",
      "real label: 0 | fitted: 0\n",
      "real label: 2 | fitted: 2\n",
      "real label: 0 | fitted: 0\n",
      "real label: 1 | fitted: 2\n",
      "real label: 2 | fitted: 2\n",
      "real label: 0 | fitted: 0\n",
      "real label: 2 | fitted: 2\n"
     ]
    }
   ],
   "source": [
    "# 1.\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "\n",
    "data = tfds.load(\"iris\", split='train')\n",
    "\n",
    "# 4.\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "input_size = 4\n",
    "output_size = 3\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 5.\n",
    "weights = tf.Variable(tf.random.normal(\n",
    "  shape=(input_size, output_size),\n",
    "  dtype=tf.float32\n",
    "))\n",
    "biases = tf.Variable(tf.random.normal(\n",
    "  shape=(output_size,),\n",
    "  dtype=tf.float32\n",
    "))\n",
    "\n",
    "# 8.\n",
    "optimizer = tf.optimizers.SGD(learning_rate)\n",
    "\n",
    "for _ in range(epochs):\n",
    "  # 2.\n",
    "  for batch in data.batch(batch_size, drop_remainder=True):\n",
    "    labels = tf.one_hot(batch['label'], 3)\n",
    "    X = batch['features']\n",
    "    X = (X - np.mean(X) / np.std(X))\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "      # 6.\n",
    "      logits = tf.add(tf.matmul(X, weights), biases) # logistic regression (actually is linear regression first)\n",
    "\n",
    "      # 7.\n",
    "      loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels, logits)\n",
    "      )\n",
    "\n",
    "    # 8.\n",
    "    gradients = tape.gradient(loss, [weights, biases])\n",
    "    optimizer.apply_gradients(zip(gradients, [weights, biases]))\n",
    "\n",
    "print(f\"final loss is: {loss.numpy():.3f}\")\n",
    "preds = tf.math.argmax(tf.add(tf.matmul(X, weights), biases), axis=1)\n",
    "ground_truth = tf.math.argmax(labels, axis=1)\n",
    "for y_true, y_pred in zip(ground_truth.numpy(), preds.numpy()):\n",
    "  print(f\"real label: {y_true} | fitted: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow computes the changes by creating a computational graph which tracks the steps taken for all operations. Graphs do not use recursion.\n",
    "\n",
    "Tensorflow keeps track of all variables in the computational graph and computes the gradients to minimize the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables and Tensors\n",
    "\n",
    "All variables are stored as tensors. Even single number/ digits are stored as zero-dimensional tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 14:51:18.603813: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-09 14:51:18.739735: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-09 14:51:18.802387: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-09 14:51:18.817166: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-09 14:51:18.916843: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_dim, col_dim = 3, 3\n",
    "ones_tsr = tf.ones([row_dim, col_dim])\n",
    "ones_tsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[42, 42, 42],\n",
       "       [42, 42, 42],\n",
       "       [42, 42, 42]], dtype=int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or a filled tensor\n",
    "tf.fill([row_dim, col_dim], value=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tensors based on an existing shape\n",
    "tf.zeros_like(ones_tsr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0.9851533 , 0.11942112, 0.5387734 ],\n",
       "       [0.4384067 , 0.9586129 , 0.19684386],\n",
       "       [0.04166341, 0.10652184, 0.03117621]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate values from distributions\n",
    "tf.random.uniform([row_dim, col_dim], minval=0, maxval=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize a tensor as a variable use `tf.Variable()`. Notice in the example below that the output is a Variable instead of tensor now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3, 3) dtype=float32, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_var = tf.Variable(tf.zeros([row_dim, col_dim]))\n",
    "my_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3]),\n",
       " <tf.Tensor: shape=(3,), dtype=int64, numpy=array([1, 2, 3])>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# to convert into a tensor\n",
    "np_arr = np.array([1, 2, 3])\n",
    "l = [1, 2, 3]\n",
    "np_arr, tf.convert_to_tensor(np_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Matrices\n",
    "\n",
    "pg 52-54 examples of elementwise operations on matrices\n",
    "\n",
    "Any custom functions created must use the tensorflow API to be used in the computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_matrix = tf.linalg.diag([1.0, 1.0, 1.0])\n",
    "A = tf.random.truncated_normal([2, 3])\n",
    "B = tf.fill([2, 3], 5.0)\n",
    "C = tf.random.uniform([3, 2])\n",
    "D = tf.convert_to_tensor(np.array([[1., 2., 3.],\n",
    "                                   [-3., -7., -1.],\n",
    "                                   [0., 5., -2.]]),\n",
    "                                   dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[6.7755075, 5.012356 , 5.9779267],\n",
       "       [4.1081805, 4.056792 , 5.404626 ]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Operations\n",
    "A + B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[ 1., -3.,  0.],\n",
       "       [ 2., -7.,  5.],\n",
       "       [ 3., -1., -2.]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(B, id_matrix)\n",
    "tf.multiply(D, id_matrix)\n",
    "tf.transpose(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-10.659076  ,  -0.22750677,   2.8865824 ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       " array([[ 0.21749546, -0.6325011 ,  0.7433963 ],\n",
       "        [ 0.84526515, -0.25879973, -0.46749282],\n",
       "        [-0.48808047, -0.7300446 , -0.47834337]], dtype=float32)>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear algebra uses the .linalg methods\n",
    "tf.linalg.det(D)\n",
    "tf.linalg.inv(D)\n",
    "tf.linalg.eigh(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Functions \n",
    "\n",
    "Introduces non-linear operations into neural networks. Careful which activation function is used and where it's used.\n",
    "\n",
    "* Adjusts weights and biases\n",
    "* Non-linear operations on tensors\n",
    "\n",
    "## A note about activation functions\n",
    "\n",
    "The computational graph is limited by the output range of the activation function i.e if the output of the activation function is between 0 and 1, then the computational graph will have a range of [0, 1]\n",
    "\n",
    "üí° Use activation functions that preserve the variance as much as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0.  3. 10.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Example of the ReLU activation function\n",
    "print(tf.nn.relu([ -3., 3., 10 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 3. 6.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Another implementation which caps the max value of the ReLU function\n",
    "## called ReLU6 which caps it at 6\n",
    "print(tf.nn.relu6([-3., 3., 10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method above is _computationally faster_, prevents the _exploding and vanishing gradient_ problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.26894143 0.5        0.73105854], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Sigmoid (logistic) function\n",
    "print(tf.nn.sigmoid([-1., 0., 1.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid function has a tendency to zero-out the backpropogation term during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-0.7615942  0.         0.7615942], shape=(3,), dtype=float32)\n",
      "tf.Tensor([0.31326172 0.6931472  1.3132616 ], shape=(3,), dtype=float32)\n",
      "tf.Tensor([-0.63212055  0.          1.        ], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Other activation functions\n",
    "# Hyperbolic tangent function - similar to Sigmoid, but (-1, 1)\n",
    "print(tf.nn.tanh([-1, 0., 1.]))\n",
    "\n",
    "# Softplus function - smoother version if ReLU function\n",
    "print(tf.nn.softplus([-1., 0., 1.]))\n",
    "\n",
    "# Exponential Linear Unit (ELU) - bottom asymptote is -1, similar to Softplus\n",
    "print(tf.nn.elu([-1., 0., 1.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-0.26894143  0.          0.73105854], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def swish(x: tf.Tensor):\n",
    "  return x * tf.nn.sigmoid(x)\n",
    "\n",
    "print(swish([-1., 0, 1.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://raw.githubusercontent.com/PacktPublishing/TensorFlow-2-Machine-Learning-Cookbook-Third-Edition/master/birthweight.dat\n",
      "\u001b[1m4554/4554\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from http://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\n",
      "  49152/Unknown \u001b[1m0s\u001b[0m 4us/step\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fbd38858ada4288a9479efbca70ee47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n",
      "Downloading data from http://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
      " 106496/Unknown \u001b[1m0s\u001b[0m 4us/stepDownloading data from http://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz\n",
      "\u001b[1m487770/487770\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3us/step\n",
      "\u001b[1mDownloading and preparing dataset 162.17 MiB (download: 162.17 MiB, generated: 132.40 MiB, total: 294.58 MiB) to /root/tensorflow_datasets/cifar10/3.0.2...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1ffb718b384796afa3ca7eca4dec15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2682f769a65477dbb03e743e81cc66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e04fa2aea2c4e9b94a299528a44df4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "# Iris dataset \n",
    "iris = tfds.load('iris', split='train')\n",
    "\n",
    "# Birth weight data - contains measurements inclusing childbirth weight\n",
    "birthdata_url = 'https://raw.githubusercontent.com/PacktPublishing/TensorFlow-2-Machine-Learning-Cookbook-Third-Edition/master/birthweight.dat' \n",
    "path = tf.keras.utils.get_file(birthdata_url.split('/')[-1], birthdata_url)\n",
    "\n",
    "def map_line(x):\n",
    "  return tf.strings.to_number(tf.strings.split(x))\n",
    "birth_file = tf.data \\\n",
    "  .TextLineDataset(path) \\\n",
    "  .skip(1) \\\n",
    "  .map(map_line)\n",
    "\n",
    "# Boston housing data - 506 observations of house worth\n",
    "housing_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'\n",
    "path = tf.keras.utils.get_file(housing_url.split(\"/\")[-1], housing_url)\n",
    "\n",
    "housing = tf.data \\\n",
    "  .TextLineDataset(path) \\\n",
    "  .map(map_line)\n",
    "\n",
    "# MNIST - handwriting data\n",
    "mnist = tfds.load('mnist', split=None)\n",
    "mnist_train = mnist['train']\n",
    "mnist_test = mnist['test']\n",
    "\n",
    "# Spam-ham text data - text message data on whether a message is spam or not\n",
    "zip_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip'\n",
    "path = tf.keras.utils.get_file(zip_url.split(\"/\")[-1], zip_url, extract=True)\n",
    "\n",
    "path = path.replace(\"smsspamcollection.zip\", \"SMSSpamCollection\")\n",
    "\n",
    "def split_text(x):\n",
    "    return tf.strings.split(x, sep='\\t')\n",
    "\n",
    "text_data = tf.data \\\n",
    "  .TextLineDataset(path) \\\n",
    "  .map(split_text)\n",
    "            \n",
    "# Moview review data - Classify whether movie is good or bad\n",
    "movie_data_url = 'http://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz'\n",
    "path = tf.keras.utils.get_file(movie_data_url.split('/')[-1], movie_data_url, extract=True)\n",
    "path = path.replace('.tar.gz', '')\n",
    "\n",
    "with open('moview_reviews.txt', 'w') as review_file:\n",
    "  for response, filename in enumerate(['/rt-polarity.neg', '/rt-polarity.pos']):\n",
    "    with open(path+filename, 'r', encoding='utf-8', errors='ignore') as movie_file:\n",
    "      for line in movie_file:\n",
    "        review_file.write(str(response) + '\\t' + line.encode('utf-8').decode())\n",
    "\n",
    "movies = tf.data \\\n",
    "  .TextLineDataset('movie_reviews.txt') \\\n",
    "  .map(split_text)\n",
    "\n",
    "# CIFAR-10 image data - labeled coloured images, 10 target classes\n",
    "ds, info = tfds.load('cifar10', shuffle_files=True, with_info=True)\n",
    "print(info)\n",
    "\n",
    "cifar_train = ds['train']\n",
    "cifar_test = ds['test']\n",
    "\n",
    "# Shakespear text data - compiled work of Shakespear\n",
    "shakespeare_url = 'https://raw.githubusercontent.com/PacktPublishing/TensorFlow-2-Machine-Learning-Cookbook-Third-Edition/master/shakespeare.txt'\n",
    "path = tf.keras.utils.get_file(shakespeare_url.split(\"/\")[-1], shakespeare_url)\n",
    "\n",
    "shakespeare_text = tf.data \\\n",
    "  .TextLineDataset(path) \\\n",
    "  .map(split_text)\n",
    "\n",
    "# English-German translation data - sentence-to-sentence translation from english to german\n",
    "import os\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "sentence_url = \"https://www.manythings.org/anki/cmn-eng.zip\"\n",
    "r = Request(\n",
    "  sentence_url,\n",
    "  headers={\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; U; Linux i686) Gecko/20071127 Firefox/2.0.0.11'\n",
    "  }\n",
    ")\n",
    "b2 = [z for z in sentence_url.split('/') if '.zip' in z][0]\n",
    "\n",
    "with open(b2, \"wb\") as target:\n",
    "  target.write(urlopen(r).read())\n",
    "\n",
    "with ZipFile(b2) as z:\n",
    "  chn = [line.split('\\t')[:2] for line in z.open('cmn.txt').read().decode().split('\\n')]\n",
    "\n",
    "os.remove(b2)\n",
    "\n",
    "with open(\"cmn.txt\", \"wb\") as chn_file:\n",
    "  for line in chn:\n",
    "    data = \",\".join(line) + \"\\n\"\n",
    "    chn_file.write(data.encode('utf-8'))\n",
    "  \n",
    "text_data = tf.data \\\n",
    "  .TextLineDataset(\"cmn.txt\") \\\n",
    "  .map(split_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Under the Hood\n",
    "\n",
    "1. Tensorflow uses eager execution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
