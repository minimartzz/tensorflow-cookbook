{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date | User | Change Type | Remarks |  \n",
    "| ---- | ---- | ----------- | ------- |\n",
    "| 09/12/2024   | Martin | Created   | Created notebook for Chp 3. Sequential model started | \n",
    "| 10/12/2024   | Martin | Update   | Completed Sequential and Functional API. Started Subclassing API | \n",
    "| 11/12/2024   | Martin | Update   | Completed Subclassing API | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Content\n",
    "\n",
    "* [Introduction](#introduction)\n",
    "* [Understanding Keras Layers](#understanding-keras-layers)\n",
    "* [Sequential API](#keras-sequential-api)\n",
    "* [Functional API](#keras-functional-api)\n",
    "* [Subclassing API](#keras-subclassing-api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a high-level API with multiple ML frameworks as its backend with Tensorflow being one of them. Provides an easy-to-use and accessible library to enable fast experimentation.\n",
    "\n",
    "Keras is the official high-level API for Tensorflow v2. It integrates TensorFlow-specific functionality like eager execution, data pipelines and Estimators, optimized for the Tensorflow backend\n",
    "\n",
    "The only difference between the Tensorflow version and the typical Keras package is in how it's imported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Keras Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras layers are the fundamental building blocks of Keras models. Each layer receives data as input, does a specific task and returns an output\n",
    "\n",
    "* __Core layers__: Dense, Activation, Flatten, Input, ...\n",
    "* __Convolutional layers__: Conv1D, Conv2D, Cropping2D, ...\n",
    "* __Pooling layers__: perform a downsampling operation/ MaxPooling1D, AveragePooling2D, ...\n",
    "* __Recurrent layers__: RNN, SimpleRNN, LSTM, ...\n",
    "* __Embedding layers__: used as the first layers to create dense vectors of fixed size to represent more complex details (e.g text data)\n",
    "* __Merge layers__: Add, Subtract, Multiply, ...\n",
    "* __Advanced activation layers__: LeakyReLU, Softmax, ...\n",
    "* __Batch normalisation layers__: normalises the activation of the previous layer at each batch\n",
    "* __Noise layers__: GausianNoise, GausianDropout, AlphaDropout\n",
    "* __Layer wrappers__: TimeDistributed applies a layer to every temporal slice of an input and bidirectional wrapper for RNNs\n",
    "* __Locally connected layers__: LocallyConnected1D and LocallyConnected2D\n",
    "* __Custom layers__: able to write custom layers using the Subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard functions used in Keras layers\n",
    "layer.get_weights() # returns weights of layer as list of NumPy arrays\n",
    "layer.set_weights(weights) # fixes the weights of the layer \n",
    "\n",
    "## For shared layers - layers that are used multiple times in the network\n",
    "layer.get_input_at(node_index)\n",
    "layer.get_output_at(node_index)\n",
    "\n",
    "## Get shape\n",
    "layer.input_shape\n",
    "layer.output_shape\n",
    "\n",
    "## Get a layers configuration, does not include weights or connectivity information\n",
    "layer.get_config()\n",
    "layer.from_config(config) # configs are stored in a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sequential models which are linear stacks of layers. The model architecture is specified and the training, tuning and testing loop is built around the model specified.\n",
    "\n",
    "The Sequential API follows the delayed-build pattern: if no input shape is specified on the first layer, the model gets built the first time the model is called on some input data.\n",
    "\n",
    "Graph is finalized with the `compile` method which configures the modle before the learning phase. Then the model is evaluated and able to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"GRPC_VERBOSITY\"] = \"ERROR\"\n",
    "os.environ[\"GLOG_minloglevel\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequential model\n",
    "\n",
    "## model here is a categorical classifier for 10 different categories\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(1024, input_dim=64), # first number represents number of nodes\n",
    "  tf.keras.layers.Activation('tanh'),\n",
    "  tf.keras.layers.Dense(256),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Activation('softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │        \u001b[38;5;34m66,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m262,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">331,530</span> (1.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m331,530\u001b[0m (1.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">331,530</span> (1.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m331,530\u001b[0m (1.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another method of declaring the model is to use the .add() method\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1024, input_dim=64))\n",
    "model.add(tf.keras.layers.Activation('tanh'))\n",
    "# ...\n",
    "model.add(tf.keras.layers.Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers can have different parameters to specify their functions\n",
    "\n",
    "## specifies the number of inputs the layer expects to receive\n",
    "Dense(256, input_dim=64)\n",
    "\n",
    "## specifies the activation function of this layer\n",
    "Dense(256, activation='sigmoid') \n",
    "\n",
    "## specifies the initialisation strategy for weights and biases\n",
    "Dense(256, kernel_initializer='random_normal') \n",
    "Dense(256, bias_initializer=tf.keras.initializers.Constant(value=5))\n",
    "\n",
    "## regularizers for kernel and bias\n",
    "Dense(256, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "Dense(256, bias_regularizer=tf.keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model compilation - specifies details abot the training mechanism\n",
    "model.compile(\n",
    "  optimizer=\"adam\", # optimisation algorithm\n",
    "  loss=\"categorical_crossentropy\", # loss function can be custom - return a scalar of loss for each data point\n",
    "  metrics=[\"accuracy\"] # metrics to judge the model performance - not used in training process\n",
    "  # use run_eagerly to evaluate eagerly\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fit - training process begins\n",
    "model.fit(\n",
    "  data,\n",
    "  labels,\n",
    "  epochs=10, # number of iterations over the entire input data\n",
    "  batch_size=50, # amount of data to process per batch\n",
    "  validation_data=(val_data, val_labels) # validation data - monitor performance of model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer configuration recommendations:\n",
    "\n",
    "1. Always set the __input shape__ for the first layer - shape must be the same as the training data. Subsequent layers can perform inference.\n",
    "2. Keras is defined to support any batch size, so only the number of features is needed to be specified. (but can be controlled using `batch_size` parameter)\n",
    "\n",
    "If the input shape is not specified, no methods can be called on the layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "data = np.random.random((2000, 64)) # 2000 entries, 64 features\n",
    "labels = np.random.random(( 2000, 10 ))\n",
    "val_data = np.random.random(( 500, 64 ))\n",
    "val_labels = np.random.random(( 500, 10 ))\n",
    "test_data = np.random.random(( 500, 64 ))\n",
    "test_labels = np.random.random(( 500, 10 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(1024, input_dim=64), # first number represents number of nodes\n",
    "  tf.keras.layers.Activation('tanh'),\n",
    "  tf.keras.layers.Dense(256),\n",
    "  tf.keras.layers.Activation('relu'),\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Activation('softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model training parameters\n",
    "model.compile(\n",
    "  optimizer=\"adam\", # optimisation algorithm\n",
    "  loss=\"categorical_crossentropy\", # loss function can be custom - return a scalar of loss for each data point\n",
    "  metrics=[\"accuracy\"] # metrics to judge the model performance - not used in training process\n",
    "  # use run_eagerly to evaluate eagerly\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733797392.590412     110 service.cc:146] XLA service 0x7fb860003c70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1733797392.590457     110 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
      "2024-12-10 02:23:12.621860: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-10 02:23:12.727804: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "2024-12-10 02:23:13.583474: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_145', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2024-12-10 02:23:14.249693: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_145', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2024-12-10 02:23:14.367767: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_284', 424 bytes spill stores, 424 bytes spill loads\n",
      "\n",
      "2024-12-10 02:23:14.482539: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_145', 200 bytes spill stores, 200 bytes spill loads\n",
      "\n",
      "2024-12-10 02:23:14.541798: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_284', 444 bytes spill stores, 444 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:02\u001b[0m 3s/step - accuracy: 0.1200 - loss: 11.2705"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733797395.266738     110 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.0993 - loss: 23.0681 - val_accuracy: 0.0920 - val_loss: 107.6519\n",
      "Epoch 2/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1017 - loss: 145.7135 - val_accuracy: 0.1100 - val_loss: 243.0333\n",
      "Epoch 3/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1044 - loss: 240.1554 - val_accuracy: 0.1000 - val_loss: 107.3819\n",
      "Epoch 4/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0834 - loss: 83.5420 - val_accuracy: 0.1000 - val_loss: 29.9293\n",
      "Epoch 5/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0907 - loss: 47.6700 - val_accuracy: 0.1180 - val_loss: 73.9437\n",
      "Epoch 6/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0957 - loss: 77.8198 - val_accuracy: 0.1180 - val_loss: 73.6665\n",
      "Epoch 7/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1102 - loss: 94.1683 - val_accuracy: 0.1180 - val_loss: 99.7233\n",
      "Epoch 8/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0974 - loss: 117.4692 - val_accuracy: 0.1000 - val_loss: 118.3626\n",
      "Epoch 9/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0882 - loss: 117.4706 - val_accuracy: 0.1000 - val_loss: 113.3767\n",
      "Epoch 10/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0806 - loss: 121.5518 - val_accuracy: 0.1000 - val_loss: 172.2888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fb95e3b6b10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "  data,\n",
    "  labels,\n",
    "  epochs=10, # number of iterations over the entire input data\n",
    "  batch_size=50, # amount of data to process per batch\n",
    "  validation_data=(val_data, val_labels) # validation data - monitor performance of model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1004 - loss: 174.2154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[173.08287048339844, 0.10100000351667404]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the models performance on training data\n",
    "model.evaluate(data, labels, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.68650632e-26, 1.08123525e-13, 9.91296702e-07, ...,\n",
       "        1.49798806e-42, 9.99966741e-01, 1.29173701e-12],\n",
       "       [3.68650632e-26, 1.08123525e-13, 9.91296702e-07, ...,\n",
       "        1.49798806e-42, 9.99966741e-01, 1.29173701e-12],\n",
       "       [3.68650632e-26, 1.08123525e-13, 9.91296702e-07, ...,\n",
       "        1.49798806e-42, 9.99966741e-01, 1.29173701e-12],\n",
       "       ...,\n",
       "       [3.68650632e-26, 1.08123525e-13, 9.91296702e-07, ...,\n",
       "        1.49798806e-42, 9.99966741e-01, 1.29173701e-12],\n",
       "       [3.68650632e-26, 1.08123525e-13, 9.91296702e-07, ...,\n",
       "        1.49798806e-42, 9.99966741e-01, 1.29173701e-12],\n",
       "       [3.68650632e-26, 1.08123525e-13, 9.91296702e-07, ...,\n",
       "        1.49798806e-42, 9.99966741e-01, 1.29173701e-12]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get results of model on test set\n",
    "model.predict(test_data, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras Sequential API is limited to a liner topology (layers can only follow one after the other). The Functional API allows defining more complex models with a non-linear topology (e.g ResNet, Inception, etc.)\n",
    "\n",
    "Multiple inputs, Multiple outputs, residual connections with non-sequential flow, and shared and reusable layers.\n",
    "\n",
    "The Functional API is a way to build a graph of layers and create more flexible models.\n",
    "\n",
    "__How it works__\n",
    "\n",
    "The Functional API works by individually defining the layers and then passing the outputs of one layer to another at each step. Like drawing the arrows between the layers manually. More time consuming but also __more configurable__ in terms of layer architecture design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, TimeDistributed\n",
    "import keras.models\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"GRPC_VERBOSITY\"] = \"ERROR\"\n",
    "os.environ[\"GLOG_minloglevel\"] = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working of the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_mnist_train, y_mnist_train), (X_mnist_test, y_mnist_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the input node\n",
    "inputs = tf.keras.Input(shape=(28, 28))\n",
    "\n",
    "# Flatten the image\n",
    "flatten_layer = keras.layers.Flatten()\n",
    "flatten_output = flatten_layer(inputs) # a layer call action - \"passing\" the output of inputs layer into flatten layer\n",
    "\n",
    "# Dense layer\n",
    "dense_layer = tf.keras.layers.Dense(50, activation='relu')\n",
    "dense_output = dense_layer(flatten_output)\n",
    "\n",
    "# Output layer\n",
    "predictions = tf.keras.layers.Dense(10, activation='softmax')(dense_output)\n",
    "\n",
    "# Define the mfinal model\n",
    "model = keras.Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">39,250</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m39,250\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m510\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,760</span> (155.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m39,760\u001b[0m (155.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,760</span> (155.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m39,760\u001b[0m (155.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1770 - loss: 336.4047 - val_accuracy: 0.2034 - val_loss: 2.0383\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2024 - loss: 2.0526 - val_accuracy: 0.2075 - val_loss: 2.0407\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2004 - loss: 2.0523 - val_accuracy: 0.2069 - val_loss: 2.0803\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2001 - loss: 2.0708 - val_accuracy: 0.2065 - val_loss: 2.0261\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2024 - loss: 2.0354 - val_accuracy: 0.2052 - val_loss: 2.0193\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.2069 - loss: 2.0265 - val_accuracy: 0.2078 - val_loss: 2.1708\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2021 - loss: 2.0479 - val_accuracy: 0.2039 - val_loss: 2.0407\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2018 - loss: 2.0479 - val_accuracy: 0.2012 - val_loss: 2.0371\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1990 - loss: 2.0534 - val_accuracy: 0.2053 - val_loss: 2.0129\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2064 - loss: 2.0159 - val_accuracy: 0.2047 - val_loss: 2.0159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fb8d8425290>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "  optimizer='sgd',\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  metrics=[ 'accuracy' ]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "  X_mnist_train,\n",
    "  y_mnist_train,\n",
    "  validation_data=(X_mnist_train, y_mnist_train),\n",
    "  epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "preds = []\n",
    "for results in model.predict(X_mnist_test):\n",
    "  preds.append(np.argmax(results))\n",
    "\n",
    "comparisons = [a == b for (a, b) in itertools.product(preds, y_mnist_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1038914\n"
     ]
    }
   ],
   "source": [
    "accuracy = sum(comparisons) / len(comparisons)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using callable models like layers\n",
    "\n",
    "Pre-existing models can be called like layers using the Functional API.\n",
    "\n",
    "1. With the Functional API, trained models can be treated as layers and outputs from a layer can be passed as inputs into these trained models.\n",
    "2. Able to account for sequenced data (e.g from an image model to a video model). There are wrappers available in the API that utilise the model to predict on every instance in the sequence (e.g `TimeDistributed`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Trained model as a layer\n",
    "x = Input(shape=(784,))\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Turning and image classification to video classification\n",
    "input_sequence = tf.keras.Input(shape=(10, 28, 28))\n",
    "processed_sequences = tf.keras.layers.TimeDistributed(model)(input_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model with multiple inputs and outputs\n",
    "\n",
    "Functional API is able to manage multiple data streams with many input and output layers.\n",
    "\n",
    "### Example\n",
    "\n",
    "Predicting the price of a specific house and the elapsed time before its sale\n",
    "\n",
    "__Inputs__\n",
    "\n",
    "1. Data about the house such as the nmber of bedrooms, house size, air conditioning, etc.\n",
    "2. A recent picture of the house\n",
    "\n",
    "__Outputs__\n",
    "\n",
    "1. Elapsed time before the sale (categorical - \"slow\", \"fast\")\n",
    "2. Predicted price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "## \"Model\" 1\n",
    "house_data_inputs = tf.keras.Input(shape=(128,), name='house_data')\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(house_data_inputs)\n",
    "block_1_output = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "## \"Model\" 2\n",
    "house_picture_inputs = tf.keras.Input(shape=(128, 128, 3), name='house_pictures')\n",
    "x = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(house_picture_inputs)\n",
    "x = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_2_output = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "## Combining the outputs\n",
    "x = tf.keras.layers.concatenate([block_1_output, block_2_output])\n",
    "\n",
    "## Logistic regression for predicted price\n",
    "pred_price = tf.keras.layers.Dense(1, activation='relu', name='price')(x)\n",
    "## Classifier for elapsed time before sale\n",
    "elapsed_time = tf.keras.layers.Dense(2, activation='softmax', name='elapsed_time')(x)\n",
    "\n",
    "## Define the final model\n",
    "model = keras.Model(\n",
    "  inputs=[house_data_inputs, house_picture_inputs],\n",
    "  outputs=[pred_price, elapsed_time],\n",
    "  name='toy_house_pred'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, 'multi_input_and_output_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Layers\n",
    "\n",
    "Some models reuse the same layer multiple times inside the architecture. These layer instances learn features that correspond to multiple paths in the graph of layers. Shared layers are often used to encode inputs from similar spaces.\n",
    "\n",
    "In the Functional API, to share layers, just instantiate it once and call it on multiple inputs\n",
    "\n",
    "### Example \n",
    "\n",
    "Embedding layer that encodes text information from 2 different inputs with similar vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable-length sequence of integers\n",
    "text_input_a = tf.keras.Input(shape=(None, ), dtype='int32')\n",
    "text_input_b = tf.keras.Input(shape=(None, ), dtype='int32')\n",
    "\n",
    "# Embedding layer\n",
    "shared_embedding = tf.keras.layers.Embedding(1000, 128)\n",
    "\n",
    "# Reuse the same layer to encode both inputs\n",
    "encode_input_a = shared_embedding(text_input_a)\n",
    "encode_input_b = shared_embedding(text_input_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting and reusing nodes in a graph of layers\n",
    "\n",
    "A node represents the computation that transforms the input to the output within the layer. Multiple nodes are contained within a layer perform the computation.\n",
    "\n",
    "`tf.keras.application` module contains canned architectures with pre-trained weights.\n",
    "\n",
    "### A note on Transfer Learning\n",
    "\n",
    "* Ability to reuse existing architectures or parts of existing architectures in new models\n",
    "* Improves training phase by decreasing the training time and model performance on related issues\n",
    "* Used as the starting point since weights are already pre-trained\n",
    "* Usually used for _weight initialisation_ and _feature extraction_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor shape=(None, 224, 224, 3), dtype=float32, sparse=None, name=keras_tensor_370>,\n",
       " <KerasTensor shape=(None, 230, 230, 3), dtype=float32, sparse=False, name=keras_tensor_371>,\n",
       " <KerasTensor shape=(None, 112, 112, 64), dtype=float32, sparse=False, name=keras_tensor_372>,\n",
       " <KerasTensor shape=(None, 112, 112, 64), dtype=float32, sparse=False, name=keras_tensor_373>,\n",
       " <KerasTensor shape=(None, 112, 112, 64), dtype=float32, sparse=False, name=keras_tensor_374>,\n",
       " <KerasTensor shape=(None, 114, 114, 64), dtype=float32, sparse=False, name=keras_tensor_375>,\n",
       " <KerasTensor shape=(None, 56, 56, 64), dtype=float32, sparse=False, name=keras_tensor_376>,\n",
       " <KerasTensor shape=(None, 56, 56, 64), dtype=float32, sparse=False, name=keras_tensor_379>,\n",
       " <KerasTensor shape=(None, 56, 56, 64), dtype=float32, sparse=False, name=keras_tensor_380>,\n",
       " <KerasTensor shape=(None, 56, 56, 64), dtype=float32, sparse=False, name=keras_tensor_381>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resnet model\n",
    "resnet = tf.keras.applications.resnet.ResNet50()\n",
    "\n",
    "# display the intermediate layers\n",
    "intermediate_layers = [layer.output for layer in resnet.layers]\n",
    "intermediate_layers[:10] # top 10 layers for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layers = intermediate_layers[:-2] # acc to the model architecture, last 2 layers are not feature layers\n",
    "\n",
    "# Can reuse these feature layers to create a feature extraction model\n",
    "feature_extraction_model = tf.keras.Model(inputs=resnet.inputs, outputs=feature_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* Functional API is more flexible and enables extracting and reusing nodes\n",
    "* Create non-linear models with multiple inputs and outputs\n",
    "* Model plotting and whole model saving\n",
    "\n",
    "### Tips & Tricks\n",
    "\n",
    "1. Name the layers\n",
    "2. Separate submodels (in your code)\n",
    "3. Review the layer summary once model is finished to verify the input and output dimensions between layers\n",
    "4. Review graph plots to check connection between each layer\n",
    "5. Use consistent variable names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Subclassing API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is based on object-oriented design principles, so able to create custom models architecture definitions.\n",
    "\n",
    "More difficult, but more customisation. It's used to build unique architectures and for those that want to have full control over their model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"GRPC_VERBOSITY\"] = \"ERROR\"\n",
    "os.environ[\"GLOG_minloglevel\"] = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a custom layer\n",
    "\n",
    "All layers are subclasses of the `Layer` class and implement these methods:\n",
    "\n",
    "* `build` - defines weights of layers\n",
    "* `call` - transformation from inputs to outputs done by layer\n",
    "* `compute_output_shape` - performs automatic shape inference\n",
    "* `get_config` & `from_config` - if the layer is serialised and deserialised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom layer\n",
    "class MyCustomDense(tf.keras.layers.Layer):\n",
    "  # Initialise the class eith the number of units\n",
    "  def __init__(self, units):\n",
    "    super(MyCustomDense, self).__init__()\n",
    "    self.units = units\n",
    "  \n",
    "  # Define the weights and bias\n",
    "  def build(self, input_shape):\n",
    "    self.w = self.add_weight(\n",
    "      shape=(input_shape[-1], self.units),\n",
    "      initializer='random_normal',\n",
    "      trainable=True\n",
    "    )\n",
    "    self.b = self.add_weight(\n",
    "      shape=(self.units,),\n",
    "      initializer='random_normal',\n",
    "      trainable=True\n",
    "    )\n",
    "  \n",
    "  # Applying this layer transformation to the input tensor\n",
    "  def call(self, inputs):\n",
    "    return tf.matmul(inputs, self.w) + self.b\n",
    "  \n",
    "  # Function to retrieve the configuration\n",
    "  def get_config(self):\n",
    "    return {'units': self.units}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.00291129 -0.00498378 -0.05527667  0.02332013]\n",
      " [-0.00291129 -0.00498378 -0.05527667  0.02332013]], shape=(2, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "x = tf.ones((2, 2))\n",
    "my_custom_layer = MyCustomDense(4)\n",
    "y = my_custom_layer(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using it in a model\n",
    "inputs = keras.Inputs((12, 4))\n",
    "outputs = MyCustomDense(2)(inputs)\n",
    "\n",
    "# Create model\n",
    "model = model.get_config()\n",
    "\n",
    "# Reload model from config\n",
    "new_model = keras.Model.from_config(\n",
    "  config,\n",
    "  custom_objects={'MyCustomDense': MyCustomDense}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a custom model\n",
    "\n",
    "Subclassing the `tf.kears.Model` class to build a fully customisable model.\n",
    "\n",
    "* `call` - defines the forward pass of the model\n",
    "* `training` - defines the different behaviour during inference and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST and greyscale it\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_mnist_train, y_mnist_train), (X_mnist_test, y_mnist_test) = mnist.load_data()\n",
    "train_mnist_features = X_mnist_train / 255\n",
    "test_mnist_features = X_mnist_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomMNIST(tf.keras.Model):\n",
    "  '''Create the custom layer for the MNIST dataset'''\n",
    "  def __init__(self, num_classes):\n",
    "    super(MyCustomMNIST, self).__init__(name='my_mnist_model')\n",
    "    self.num_classes = num_classes\n",
    "\n",
    "    # defining the layers\n",
    "    self.flatten_1 = tf.keras.layers.Flatten()\n",
    "    self.dropout = tf.keras.layers.Dropout(0.1)\n",
    "    self.dense_1 = tf.keras.layers.Dense(50, activation='relu')\n",
    "    self.dense_2 = tf.keras.layers.Dense(10, activation='softmax')\n",
    "  \n",
    "  def call(self, inputs, training=False):\n",
    "    x = self.flatten_1(inputs)\n",
    "    x = self.dense_1(x)\n",
    "    # apply the dropout layer if it is training loop\n",
    "    if training:\n",
    "      x = self.dropout(x)\n",
    "    return self.dense_2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mnist_model = MyCustomMNIST(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733877178.913015     153 service.cc:146] XLA service 0x7f92f8005930 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1733877178.913239     153 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
      "2024-12-11 00:32:58.947143: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-11 00:32:58.999313: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  65/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1642 - loss: 2.2828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733877179.705877     153 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.6531 - loss: 1.1838 - val_accuracy: 0.8982 - val_loss: 0.3870\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 901us/step - accuracy: 0.8769 - loss: 0.4315 - val_accuracy: 0.9119 - val_loss: 0.3155\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 995us/step - accuracy: 0.8979 - loss: 0.3527 - val_accuracy: 0.9193 - val_loss: 0.2802\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 994us/step - accuracy: 0.9108 - loss: 0.3159 - val_accuracy: 0.9270 - val_loss: 0.2567\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9159 - loss: 0.2944 - val_accuracy: 0.9325 - val_loss: 0.2357\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9219 - loss: 0.2681 - val_accuracy: 0.9369 - val_loss: 0.2220\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9271 - loss: 0.2586 - val_accuracy: 0.9409 - val_loss: 0.2092\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9320 - loss: 0.2397 - val_accuracy: 0.9436 - val_loss: 0.1972\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9334 - loss: 0.2293 - val_accuracy: 0.9456 - val_loss: 0.1885\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9375 - loss: 0.2216 - val_accuracy: 0.9477 - val_loss: 0.1796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f93fae5be10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mnist_model.compile(\n",
    "  optimizer='sgd',\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "my_mnist_model.fit(\n",
    "  train_mnist_features,\n",
    "  y_mnist_train,\n",
    "  validation_data=(test_mnist_features, y_mnist_test),\n",
    "  epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* Uses object-oriented design patterns to create the model\n",
    "* Recommended to only be used if the Functional or Sequential API is unable to fulfill the task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
