{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date | User | Change Type | Remarks |  \n",
    "| ---- | ---- | ----------- | ------- |\n",
    "| 30/12/2024   | Martin | Created   | Started Linear Regression section. Completed estimators section. Working on mixed input model to adapt `DenseFeatures` since it's deprecated | \n",
    "| 31/12/2024   | Martin | Created   | Completed L1 and L2 error section. Did not create mixed input model, but a `FeatureSpace` model  | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Content\n",
    "\n",
    "* [Introduction](#introduction)\n",
    "* [Tensorflow and Linear Regression](#tensorflow-and-linear-regression)\n",
    "* [Note on Estimators](#note-on-estimators)\n",
    "* [Understanding Loss Functions in Linear Regression](#understanding-loss-functions-in-lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is a fundamental algorithm in Machine Learning. One key benefit it has is that it is very interpretable. Each coefficient represents a direct change (in magnitude and direction) of the final prediction.\n",
    "\n",
    "Tensorflow offers 2 ways to implement linear regression: _Estimators_ and _Keras_. \n",
    "\n",
    "Goals of module:\n",
    "\n",
    "* Tensorflow way of regression\n",
    "* Turning a Keras model into an Estimator\n",
    "* Understanding the loss functions in linear regression\n",
    "* Implementing Lasso and Ridge regression\n",
    "* Implementing logistic regression\n",
    "* Resorting to non-linear regression\n",
    "* Using Wide & Deep models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow and Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimatros and Keras provide the API to implement linear regression\n",
    "\n",
    "__Estimators__\n",
    "\n",
    "Pre-made specific procedures created to simplify training, evaluation, prediction and exporting of models. Estimators can be deployed on any hardware to serve a trained model.\n",
    "\n",
    "4 steps when developing an Estimator model:\n",
    "\n",
    "1. Acquire data (using `tf.data` fucntion)\n",
    "2. Instantiate the feature columns\n",
    "3. Instantiate and train the Estimator\n",
    "4. Evaluate the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"GRPC_VERBOSITY\"] = \"ERROR\"\n",
    "os.environ[\"GLOG_minloglevel\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20046/4286153583.py:7: FutureWarning: The 'delim_whitespace' keyword in pd.read_table is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_table(path, delim_whitespace=True, header=None, names=columns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve data\n",
    "tfds.disable_progress_bar()\n",
    "housing_url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\"\n",
    "path = tf.keras.utils.get_file(housing_url.split(\"/\")[-1], housing_url)\n",
    "\n",
    "columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "data = pd.read_table(path, delim_whitespace=True, header=None, names=columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "np.random.seed(1)\n",
    "train = data.sample(frac=0.8).copy()\n",
    "y_train = train['MEDV']\n",
    "train.drop('MEDV', axis=1, inplace=True)\n",
    "\n",
    "test = data.loc[~data.index.isin(train.index)].copy()\n",
    "y_test = test['MEDV']\n",
    "test.drop('MEDV', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_feature_columns(data_df, categorical_cols, numeric_cols):\n",
    "  feature_columns = []\n",
    "\n",
    "  for feature_name in numeric_cols:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
    "\n",
    "  for feature_name in categorical_cols:\n",
    "    vocabulary = data_df[feature_name].unique()\n",
    "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "  \n",
    "  return feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=256):\n",
    "\n",
    "  def input_function():\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(1000)\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    return ds\n",
    "  \n",
    "  return input_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['CHAS', 'RAD']\n",
    "numeric_cols = ['CRIM', 'ZN', 'INDUS',  'NOX', 'RM', 'AGE', 'DIS', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "feature_columns = define_feature_columns(data, categorical_cols, numeric_cols)\n",
    "\n",
    "train_input_fn = make_input_fn(train, y_train, num_epochs=1400)\n",
    "test_input_fn = make_input_fn(test, y_test, shuffle=False, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_est = tf.estimator.LinearRegresor(feature_columns=feature_columns)\n",
    "linear_est.train(train_input_fn)\n",
    "results = linear_est.evaluate(test_input_fn)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‼️ _Note: Estimators are no longer supported in TF as of 2.16_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "Estimators sift the data from data functions, and converts them to the proper form based on the matched feature name and feature column. Convergence to the line of best fit depends on the number of iterations, batch size, learning rate, and loss function. \n",
    "\n",
    "Good to observe the loss function over time (in real-time) to troubleshoot model problems or hyperparameter changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactions to improve performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create combination of two variables to better explain the target value compared to individual features. e.g average room number in a house and proportion of lower income population in an area reveals more about the type of neighbourhood.\n",
    "\n",
    "`tf.feature_column.crossed_column` - creates a combined categorical value and applies a hashing function to limit the cardinality of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interactions(interactions_list, buckets=5):\n",
    "    interactions = list()\n",
    "    for (a, b) in interactions_list:\n",
    "        interactions.append(tf.feature_column.crossed_column([a, b], hash_bucket_size=buckets))\n",
    "    return interactions\n",
    "\n",
    "derived_feature_columns = create_interactions([['RM', 'LSTAT']])\n",
    "linear_est = tf.estimator.LinearRegressor(feature_columns=feature_columns+derived_feature_columns)\n",
    "linear_est.train(train_input_fn)\n",
    "result = linear_est.evaluate(test_input_fn)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note on Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `tf.estimators` API has been deprecated as of version 2.15, any sections containing the API will be skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Loss Functions in LR \n",
    "\n",
    "Comparison between Mean Absolute loss (L1 Loss) and Mean Squared Loss (L2 Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tensorboard extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import FeatureSpace\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"GRPC_VERBOSITY\"] = \"ERROR\"\n",
    "os.environ[\"GLOG_minloglevel\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20046/14928026.py:9: FutureWarning: The 'delim_whitespace' keyword in pd.read_table is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_table(path, delim_whitespace=True, header=None, names=columns)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "# Retrieve data\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "housing_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'\n",
    "path = tf.keras.utils.get_file(housing_url.split(\"/\")[-1], housing_url)\n",
    "\n",
    "columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "data = pd.read_table(path, delim_whitespace=True, header=None, names=columns)\n",
    "# data['RM_int'] = round(data['RM']).astype(int) # Converting RM to integer by rounding\n",
    "# data['LSTAT_int'] = round(data['LSTAT']).astype(int) # Converting LSTAT to integer by rounding\n",
    "\n",
    "# Split into train and test data\n",
    "np.random.seed(1)\n",
    "train = data.sample(frac=0.8).copy()\n",
    "y_train = train['MEDV']\n",
    "train.drop('MEDV', axis=1, inplace=True)\n",
    "\n",
    "test = data.loc[~data.index.isin(train.index)].copy()\n",
    "y_test = test['MEDV']\n",
    "test.drop('MEDV', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe into tensor dataset\n",
    "def dataframe_to_dataset(x, y):\n",
    "  ds = tf.data.Dataset.from_tensor_slices(( x.to_dict(orient='list'), y ))\n",
    "  ds = ds.shuffle(buffer_size=len(x))\n",
    "  return ds\n",
    "\n",
    "train_ds = dataframe_to_dataset(train, y_train).batch(32).repeat(1400)\n",
    "test_ds = dataframe_to_dataset(test, y_test).batch(32).repeat(1400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_space(numeric_cols, categorical_cols, crossed_cols):\n",
    "  \"\"\"\n",
    "  A FeatureSpace helps to create a preprocessing pipeline that maps features to the\n",
    "  right data types and performs additional feature engineering tasks like feature crossing\n",
    "  \"\"\"\n",
    "  feature_space_mapping = {}\n",
    "\n",
    "  # Define the data type\n",
    "  for col in numeric_cols:\n",
    "    feature_space_mapping[col] = 'float'\n",
    "  \n",
    "  for col in categorical_cols:\n",
    "    feature_space_mapping[col] = 'integer_categorical'\n",
    "\n",
    "  for col in crossed_cols:\n",
    "    feature_space_mapping[col] = FeatureSpace.float_discretized(num_bins=7)\n",
    "  \n",
    "  # Create the FeatureSpace object\n",
    "  feature_space = FeatureSpace(\n",
    "    features=feature_space_mapping,\n",
    "    crosses=[(\"RM\", \"LSTAT\")], # RM_int because crosses only accepts int and string data\n",
    "    output_mode='concat',\n",
    "    crossing_dim=5\n",
    "  )\n",
    "\n",
    "  return feature_space\n",
    "\n",
    "categorical_cols = ['CHAS', 'RAD']\n",
    "numeric_cols = ['CRIM', 'ZN', 'INDUS',  'NOX', 'RM', 'AGE', 'DIS', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "crossed_cols = ['RM', 'LSTAT']\n",
    "\n",
    "# Instantiate the FeatureSpace class\n",
    "feature_space = create_feature_space(numeric_cols, categorical_cols, crossed_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-31 07:16:24.820700: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-31 07:16:27.557097: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-31 07:16:30.350055: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-31 07:17:18.618645: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# \"Train\" the feature space on training data without labels\n",
    "train_ds_with_no_labels = train_ds.map(lambda x, _: x)\n",
    "feature_space.adapt(train_ds_with_no_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed_x shape: (32, 41)\n",
      "preprocessed_x sample: \n",
      "[4.0500e+01 3.9290e+02 0.0000e+00 1.0000e+00 0.0000e+00 1.4320e-02\n",
      " 8.3248e+00 1.3200e+00 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 4.1100e-01 1.5100e+01 0.0000e+00\n",
      " 0.0000e+00 1.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 1.0000e+00 0.0000e+00 2.5600e+02 1.0000e+02\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 1.0000e+00]\n"
     ]
    }
   ],
   "source": [
    "# Example of feature output of feature space\n",
    "for x, _ in train_ds.take(1):\n",
    "    preprocessed_x = feature_space(x)\n",
    "    print(f\"preprocessed_x shape: {preprocessed_x.shape}\")\n",
    "    print(f\"preprocessed_x sample: \\n{preprocessed_x[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs the data transformation on each batch of data while current set of data is training\n",
    "## num_parallel_calls - number of CPUs to use while performing this function. AUTOTUNE lets TF decide optimal\n",
    "## .prefetch - ensures that the next batch of data is retrieved while current batch is training\n",
    "preprocessed_train_ds = train_ds.map(\n",
    "  lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "preprocessed_valid_ds = test_ds.map(\n",
    "  lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ").prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - L2 Error (Mean Squared Error)\n",
    "# Input layer\n",
    "encoded_features = feature_space.get_encoded_features()\n",
    "\n",
    "# Batch normalisation\n",
    "norm_layer = keras.layers.BatchNormalization()(encoded_features)\n",
    "\n",
    "# Output\n",
    "output_layer = keras.layers.Dense(1, kernel_initializer='normal', activation='linear')(norm_layer)\n",
    "\n",
    "model = keras.Model(inputs=encoded_features, outputs=output_layer)\n",
    "optmiser = keras.optimizers.Ftrl(learning_rate=0.02)\n",
    "model.compile(optimizer=optmiser, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ keras_tensor_19CLONE            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">164</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ keras_tensor_19CLONE            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m)             │           \u001b[38;5;34m164\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m42\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">206</span> (824.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m206\u001b[0m (824.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124</span> (496.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m124\u001b[0m (496.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82</span> (328.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m82\u001b[0m (328.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735626430.245768   18860 service.cc:146] XLA service 0x7fbb3c03e8f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1735626430.245863   18860 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
      "2024-12-31 06:27:10.261752: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-31 06:27:10.305908: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "I0000 00:00:1735626430.552276   18860 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18200/18200 - 23s - 1ms/step - accuracy: 0.0000e+00 - loss: 24.2498 - val_accuracy: 0.0000e+00 - val_loss: 24.5685\n",
      "Epoch 2/5\n",
      "18200/18200 - 17s - 931us/step - accuracy: 0.0000e+00 - loss: 19.4317 - val_accuracy: 0.0000e+00 - val_loss: 23.9247\n",
      "Epoch 3/5\n",
      "18200/18200 - 17s - 931us/step - accuracy: 0.0000e+00 - loss: 19.3068 - val_accuracy: 0.0000e+00 - val_loss: 23.6952\n",
      "Epoch 4/5\n",
      "18200/18200 - 18s - 968us/step - accuracy: 0.0000e+00 - loss: 19.2773 - val_accuracy: 0.0000e+00 - val_loss: 23.5556\n",
      "Epoch 5/5\n",
      "18200/18200 - 18s - 980us/step - accuracy: 0.0000e+00 - loss: 19.1586 - val_accuracy: 0.0000e+00 - val_loss: 23.4690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fbc3a6b1390>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  preprocessed_train_ds,\n",
    "  validation_data=preprocessed_valid_ds,\n",
    "  epochs=5,\n",
    "  verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n",
      "The predicted value is 25.72 | Actual value: 21.6\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "The predicted value is 34.62 | Actual value: 33.4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "The predicted value is 17.04 | Actual value: 27.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "The predicted value is 19.44 | Actual value: 19.9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "The predicted value is 14.25 | Actual value: 15.2\n"
     ]
    }
   ],
   "source": [
    "inference_model = keras.Model(\n",
    "  inputs=feature_space.get_inputs(),\n",
    "  outputs=model(encoded_features)\n",
    ")\n",
    "\n",
    "# Sample first 5 data for testing\n",
    "sample_test = test.iloc[:5]\n",
    "y_sample_test = y_test[:5]\n",
    "\n",
    "# Convert to featureSpace format and predict\n",
    "for i in range(5):\n",
    "  item = sample_test.to_dict(orient='records')[i]\n",
    "  input_dict = {\n",
    "    name: keras.ops.convert_to_tensor([value]) for name, value in item.items()\n",
    "  }\n",
    "  prediction = inference_model.predict(input_dict)[0][0]\n",
    "  actual = y_sample_test.iloc[i]\n",
    "\n",
    "  print(f\"The predicted value is {prediction:.2f} | Actual value: {actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - L1 Error (Mean Squared Error)\n",
    "# Input layer\n",
    "encoded_features = feature_space.get_encoded_features()\n",
    "\n",
    "# Batch normalisation\n",
    "norm_layer = keras.layers.BatchNormalization()(encoded_features)\n",
    "\n",
    "# Output\n",
    "output_layer = keras.layers.Dense(1, kernel_initializer='normal', activation='linear')(norm_layer)\n",
    "\n",
    "model = keras.Model(inputs=encoded_features, outputs=output_layer)\n",
    "optmiser = keras.optimizers.Ftrl(learning_rate=0.02)\n",
    "model.compile(optimizer=optmiser, loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735629461.310148   20142 service.cc:146] XLA service 0x255e9bf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1735629461.310261   20142 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
      "2024-12-31 07:17:41.325479: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-31 07:17:41.371769: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "I0000 00:00:1735629461.576444   20142 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18200/18200 - 18s - 1ms/step - loss: 3.3440 - val_loss: 3.1813\n",
      "Epoch 2/5\n",
      "18200/18200 - 19s - 1ms/step - loss: 3.0084 - val_loss: 3.1562\n",
      "Epoch 3/5\n",
      "18200/18200 - 18s - 969us/step - loss: 2.9919 - val_loss: 3.1438\n",
      "Epoch 4/5\n",
      "18200/18200 - 17s - 951us/step - loss: 2.9802 - val_loss: 3.1339\n",
      "Epoch 5/5\n",
      "18200/18200 - 17s - 912us/step - loss: 2.9779 - val_loss: 3.1294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f68ef6c78d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  preprocessed_train_ds,\n",
    "  validation_data=preprocessed_valid_ds,\n",
    "  epochs=5,\n",
    "  verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
      "The predicted value is 27.28 | Actual value: 21.6\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "The predicted value is 33.14 | Actual value: 33.4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "The predicted value is 22.10 | Actual value: 27.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "The predicted value is 19.97 | Actual value: 19.9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "The predicted value is 20.37 | Actual value: 15.2\n"
     ]
    }
   ],
   "source": [
    "inference_model = keras.Model(\n",
    "  inputs=feature_space.get_inputs(),\n",
    "  outputs=model(encoded_features)\n",
    ")\n",
    "\n",
    "# Sample first 5 data for testing\n",
    "sample_test = test.iloc[:5]\n",
    "y_sample_test = y_test[:5]\n",
    "\n",
    "# Convert to featureSpace format and predict\n",
    "for i in range(5):\n",
    "  item = sample_test.to_dict(orient='records')[i]\n",
    "  input_dict = {\n",
    "    name: keras.ops.convert_to_tensor([value]) for name, value in item.items()\n",
    "  }\n",
    "  prediction = inference_model.predict(input_dict)[0][0]\n",
    "  actual = y_sample_test.iloc[i]\n",
    "\n",
    "  print(f\"The predicted value is {prediction:.2f} | Actual value: {actual}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note of the difference between `FeatureSpace.get_inputs()` and `FeatureSpace.get_encoded_features()`\n",
    "\n",
    "* `get_inputs()` - retrieves a dictionary of Keras Input objects that correspond to the raw features defined in the `FeatureSpace`. These inputs are used to specify the shape and type of data that the model will accept during training and inference.\n",
    "\n",
    "* `get_encoded_features()` - returns the corresponding encoded Keras tensors that have been preprocessed according to the specified feature encoding strategies. This is the output that will be fed into the model for training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CRIM': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=CRIM>,\n",
       " 'ZN': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=ZN>,\n",
       " 'INDUS': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=INDUS>,\n",
       " 'NOX': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=NOX>,\n",
       " 'RM': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=RM>,\n",
       " 'AGE': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=AGE>,\n",
       " 'DIS': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=DIS>,\n",
       " 'TAX': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=TAX>,\n",
       " 'PTRATIO': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=PTRATIO>,\n",
       " 'B': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=B>,\n",
       " 'LSTAT': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=LSTAT>,\n",
       " 'CHAS': <KerasTensor shape=(None, 1), dtype=int32, sparse=None, name=CHAS>,\n",
       " 'RAD': <KerasTensor shape=(None, 1), dtype=int32, sparse=None, name=RAD>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_space.get_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 41), dtype=float32, sparse=False, name=keras_tensor_19>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_space.get_encoded_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful resources for code examples\n",
    "\n",
    "* [End-to-end FeatureSpace Keras Model](https://keras.io/examples/structured_data/feature_space_advanced/)\n",
    "* [Converting from pandas df to tensorflow dataset](https://www.tensorflow.org/tutorials/load_data/pandas_dataframe)\n",
    "* [Mixed input model tutorial](https://www.youtube.com/watch?v=4-O14gOdRso)\n",
    "* [Tensorflow docs on FeatureSpace](https://www.tensorflow.org/api_docs/python/tf/keras/utils/FeatureSpace#feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
